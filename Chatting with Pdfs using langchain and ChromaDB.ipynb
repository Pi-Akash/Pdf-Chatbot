{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6e8e4b-1a73-4702-bf68-cfd94a5d3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install these packages for using langchain and reading documents\n",
    "#!pip install --q unstructured langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833436ae-2a32-44ce-9bae-e79632aa5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab4af41-be33-4c67-a47b-a21b8f179d35",
   "metadata": {},
   "source": [
    "### Reading Pdf Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633f6225-34a3-4aa7-837a-fcd2c6169f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf file location\n",
    "localpath = \"C:/Drive D/Documents/Why should I trust you.pdf\"\n",
    "\n",
    "# read the file from the location\n",
    "try:\n",
    "    pdf_loader = UnstructuredPDFLoader(file_path = localpath)\n",
    "    pdf_data = pdf_loader.load()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5851c9b-7635-47ca-8f37-952c2eb79b4e",
   "metadata": {},
   "source": [
    "### Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f1e699-99b6-47b9-9e31-fddd7fac51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to download the nomic embed text model into local\n",
    "# !ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199b1792-927b-4154-b660-fd61cf51ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to download the gemma:2b model into local\n",
    "# !ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ee5640-9fa9-4a74-864b-c96fcaf33e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   \tID          \tSIZE  \tMODIFIED       \n",
      "gemma:2b               \tb50d6c999e59\t1.7 GB\t36 seconds ago\t\n",
      "nomic-embed-text:latest\t0a109f422b47\t274 MB\t3 minutes ago \t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee2142d-9bae-4ac1-a28a-639c67722ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install chromadb in local\n",
    "#!pip install --q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d13689-2bbf-49a2-8dbb-fa985dc1e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install langchain text splitters in local\n",
    "#!pip install -q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823d595d-7a78-4d9f-a46d-1bf9aa5aa1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a8e237-9d21-4009-bc12-11d621322e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap = 20)\n",
    "chunks = text_splitter.split_documents(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76b5248a-9053-40f2-b22a-acc1d021701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 38/38 [02:36<00:00,  4.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add the data into vector DB\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = OllamaEmbeddings(model = \"nomic-embed-text\", show_progress = True),\n",
    "    collection_name = \"local-chroma-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e70ac-0b27-4614-b0d4-51c16fcbeace",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d12e9135-8d47-4087-bce9-9e1b50496922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97c15c56-1fa3-496c-ab6a-50cd676f0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm from google\n",
    "local_model = \"gemma:2b\"\n",
    "llm = ChatOllama(model = local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1de750-c552-4902-bc56-71da6e230b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56dd5800-04ca-47f4-844f-064ea166df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f04fb78-8312-431d-9813-d52d98f38351",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26522a8e-f238-4a8a-bd75-a947c812d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What this document is about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The document is about explaining how to select and trust models for machine learning tasks. It gives insights into selecting the most relevant features for explanations, and helps users assess the trust of predictions.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe6084-614a-4559-adab-a984cb86c5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
